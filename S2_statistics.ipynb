{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Manifold Statistics - Examples on $\\mathbb{S}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.manifolds.S2 import *\n",
    "M = S2()\n",
    "print(M)\n",
    "from src.plotting import *\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemannian structure\n",
    "from src.Riemannian import metric\n",
    "metric.initialize(M)\n",
    "\n",
    "# geodesics\n",
    "from src.Riemannian import geodesic\n",
    "geodesic.initialize(M)\n",
    "\n",
    "# Logarithm map\n",
    "from src.Riemannian import Log\n",
    "Log.initialize(M)\n",
    "\n",
    "x = M.coords(jnp.zeros(M.dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coordinate form\n",
    "from src.stochastics import Brownian_coords\n",
    "Brownian_coords.initialize(M)\n",
    "\n",
    "# product sde\n",
    "from src.stochastics import product_sde\n",
    "from src.stochastics.product_sde import tile\n",
    "(product,sde_product,chart_update_product) = product_sde.initialize(M,M.sde_Brownian_coords,M.chart_update_Brownian_coords)\n",
    "\n",
    "N = 32\n",
    "_dts = dts(T=.5)\n",
    "(ts,xss,chartss,*_) = product(tile(x,N),_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),jnp.repeat(1.,N))\n",
    "samples = xss[-1]\n",
    "chartss = chartss[-1]    \n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "for i in range(N):\n",
    "    M.plotx((samples[i],chartss[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.statistics import Frechet_mean\n",
    "Frechet_mean.initialize(M)\n",
    "\n",
    "m,loss,iterations,vs = M.Frechet_mean(zip(samples,chartss),x)\n",
    "# m,loss,iterations = M.Frechet_mean(zip(samples,chartss),x,Log=lambda *args: M.Log(*args))\n",
    "print(\"loss = \", loss)\n",
    "print(\"mean = \", m)\n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "M.plotx(m,s=100,color='g')\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    try:\n",
    "        (xs,charts) = M.Expt(m,vs[i])\n",
    "        M.plot_path(zip(xs,charts))\n",
    "    except:\n",
    "        pass\n",
    "    M.plotx((samples[i],chartss[i]),linewidth = 1.5, s=50, color='r')\n",
    "M.plot_path(iterations,color='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangent PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.statistics.tangent_PCA import *\n",
    "\n",
    "from src.utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = tangent_PCA(M, lambda *args: M.Log(*args),x,zip(samples,chartss))\n",
    "print(pca.get_covariance())\n",
    "\n",
    "plt.scatter(pca.transformed_Logs[:, 0], pca.transformed_Logs[:, 1])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampled mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# condition on diagonal of product manifold\n",
    "from src.stochastics import diagonal_conditioning\n",
    "diagonal_conditioning.initialize(M,sde_product,chart_update_product)\n",
    "\n",
    "_dts = dts(n_steps=500,T=.1)\n",
    "(ts,xss,_chartss) = M.diagonal((samples,chartss),\n",
    "                             _dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),x[1],jnp.repeat(1.,N))\n",
    "mean = jnp.mean(jax.vmap(lambda _x,chart: M.update_coords((_x,chart),x[1])[0],0)(xss[-1],_chartss[-1]),0)\n",
    "\n",
    "# plot\n",
    "M.newfig()\n",
    "M.plot()\n",
    "colormap = plt.get_cmap('winter')\n",
    "colors=[colormap(k) for k in np.linspace(0, 1, N)]\n",
    "for i in range(N):\n",
    "    M.plot_path(zip(xss[:,i],_chartss[:,i]),color=colors[i])\n",
    "    M.plotx((samples[i],chartss[i]),s=40)\n",
    "M.plotx((mean,x[1]),color='r',s=80)\n",
    "ax = plt.gcf().gca(); ax.view_init(60, 45) # rotate\n",
    "plt.axis('off')\n",
    "# plt.savefig('diagonal-mean-N3.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# samples\n",
    "N = 256\n",
    "_dts = dts(T=.5)\n",
    "(ts,xss,chartss,*_) = product((jnp.tile(x[0],(N,)+(1,)*x[0].ndim),jnp.tile(x[1],(N,)+(1,)*x[1].ndim)),\n",
    "                             _dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),jnp.repeat(1.,N))\n",
    "samples = xss[-1]\n",
    "charts_samples = chartss[-1]    \n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "for i in range(N):\n",
    "    M.plotx((samples[i],charts_samples[i]))\n",
    "ax = plt.gcf().gca(); ax.view_init(60, 45) # rotate\n",
    "plt.axis('off')\n",
    "# plt.savefig('diagonal-samples-N256.pdf')\n",
    "plt.show()\n",
    "\n",
    "# sample multiple means\n",
    "K = 32\n",
    "means = np.zeros((K,M.dim))\n",
    "\n",
    "_dts = dts(T=.2)\n",
    "for i in range(K):\n",
    "    (ts,xss,_chartss) = M.diagonal((samples,charts_samples),\n",
    "                             _dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),x[1],jnp.repeat(1.,N))\n",
    "    means[i] = jnp.mean(jax.vmap(lambda _x,chart: M.update_coords((_x,chart),x[1])[0],0)(xss[-1],_chartss[-1]),0)\n",
    "    \n",
    "colormap = plt.get_cmap('winter')\n",
    "colors=[colormap(k) for k in np.linspace(0, 1, K)]\n",
    "\n",
    "# plot estimated means with std variation\n",
    "M.newfig()\n",
    "M.plot()\n",
    "ax = plt.gca()\n",
    "for j in range(K):\n",
    "    M.plotx((means[j],x[1]),color=colors[j],s=30)\n",
    "ax = plt.gcf().gca(); ax.view_init(60, 45) # rotate\n",
    "plt.axis('off')\n",
    "# plt.savefig('diagonal-mean-N256.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion mean estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Delyon/Hu guided process\n",
    "from src.stochastics.guided_process import *\n",
    "\n",
    "# guide function\n",
    "phi = lambda q,v,s: jnp.tensordot((1/s)*jnp.linalg.cholesky(M.g(q)).T,M.StdLog(q,M.F((v,q[1]))).flatten(),(1,0))\n",
    "\n",
    "(Brownian_coords_guided,sde_Brownian_coords_guided,chart_update_Brownian_coords_guided) = get_guided(\n",
    "    M,M.sde_Brownian_coords,M.chart_update_Brownian_coords,phi,\n",
    "    sqrtCov=lambda x,s: s*jnp.linalg.cholesky(M.gsharp(x)),A=lambda x,v,w,s: jnp.dot(v,jnp.dot((s**(-2))*M.g(x),w)))\n",
    "\n",
    "# product bridge sde\n",
    "from src.stochastics import product_sde\n",
    "from src.stochastics.product_sde import tile\n",
    "(product_guided,*_) = product_sde.initialize(M,sde_Brownian_coords_guided,chart_update_Brownian_coords_guided)\n",
    "\n",
    "x = M.coords(jnp.zeros(M.dim))\n",
    "w = M.Exp(x,np.array([.8,-.5])) # target\n",
    "N = 4\n",
    "_dts = dts(n_steps=1000,T=.1)\n",
    "(ts,xss,chartss,*_) = product_guided(tile(x,N),_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),\n",
    "                                     tile(0.,N),tile(0.,N),tile(jnp.sum(_dts),N),\n",
    "                                     tile(M.update_coords(w,x[1])[0],N),jnp.repeat(1.,N)) # target\n",
    "\n",
    "# plot\n",
    "M.newfig()\n",
    "M.plot()\n",
    "colormap = plt.get_cmap('winter')\n",
    "colors=[colormap(k) for k in np.linspace(0, 1, N)]\n",
    "for i in range(N):\n",
    "    M.plot_path(zip(xss[:,i],chartss[:,i]),color=colors[i])\n",
    "M.plotx(x,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def log_p_T(guided,phi,x,v,_dts,dWs,*ys):\n",
    "    \"\"\" Monte Carlo approximation of log transition density from guided process \"\"\"\n",
    "    T = jnp.sum(_dts)\n",
    "    \n",
    "    print(*ys)\n",
    "    \n",
    "    Cxv = jnp.sum(phi(x,M.update_coords(v,x[1])[0],*ys)**2)\n",
    "    \n",
    "    # sample\n",
    "    log_varphis = jax.vmap(lambda dW: guided(x,v,_dts,dW,*ys)[4][-1],1)(dWs)\n",
    "    \n",
    "    log_varphi = jnp.log(jnp.mean(jnp.exp(log_varphis)))\n",
    "    log_p_T = -.5*x[0].shape[0]*jnp.log(2.*jnp.pi*T)-Cxv/(2.*T)+log_varphi\n",
    "    return log_p_T\n",
    "\n",
    "log_p_T = partial(log_p_T,Brownian_coords_guided,phi)\n",
    "\n",
    "_dts = dts(n_steps=100,T=1.)\n",
    "\n",
    "# test one sample\n",
    "N=1 \n",
    "log_p_T(x,w,_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),1.)\n",
    "%time log_p_T(x,w,_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),1.)\n",
    "N=10\n",
    "log_p_T(x,w,_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),1.)\n",
    "%time log_p_T(x,w,_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),1.)\n",
    "N=1000\n",
    "log_p_T(x,w,_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),1.)\n",
    "%time log_p_T(x,w,_dts,dWs(N*M.dim,_dts).reshape(-1,N,M.dim),1.)\n",
    "\n",
    "# multiple samples\n",
    "N=100\n",
    "neg_log_p_Ts = lambda *args: -jnp.mean(jax.vmap(lambda x,chart,w,dW,*ys: log_p_T((x,chart),w,_dts,dW,*ys),(None,None,0,0,*((None,)*(len(args)-4))))(*args))\n",
    "neg_log_p_Ts(*x,(samples,charts_samples),dWs(samples.shape[0]*N*M.dim,_dts).reshape(-1,_dts.shape[0],N,M.dim),1.)\n",
    "%time neg_log_p_Ts(*x,(samples,charts_samples),dWs(samples.shape[0]*N*M.dim,_dts).reshape(-1,_dts.shape[0],N,M.dim),1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run MLE\n",
    "\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "def iterative_mle(obss,neg_log_p_Ts,params,params_inds,params_update,chart,step_size=1e-1,num_steps=5):\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "\n",
    "    def step(step, params, opt_state, chart):\n",
    "        params = get_params(opt_state)\n",
    "        value,grads = jax.value_and_grad(neg_log_p_Ts,params_inds)(params[0],chart,obss,\n",
    "                                                                      dWs(len(obss[0])*N*M.dim,_dts).reshape(-1,_dts.shape[0],N,M.dim),\n",
    "                                                                  *params[1:])\n",
    "        opt_state = opt_update(step, grads, opt_state)\n",
    "        opt_state,chart = params_update(opt_state, chart)\n",
    "        return (value,opt_state,chart)\n",
    "\n",
    "    opt_state = opt_init(params)\n",
    "    values = (); paramss = ()\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        (value, opt_state, chart) = step(i, params, opt_state, chart)\n",
    "        values += (value,); paramss += ((*get_params(opt_state),chart),)\n",
    "        if i % 1 == 0:\n",
    "            print(\"Step {} | T: {:0.6e} | T: {}\".format(i, value, str((get_params(opt_state),chart))))\n",
    "    print(\"Final {} | T: {:0.6e} | T: {}\".format(i, value, str(get_params(opt_state))))\n",
    "    \n",
    "    return (get_params(opt_state),chart,value,jnp.array(values),paramss)\n",
    "\n",
    "# define parameters\n",
    "x = M.coords(jnp.zeros(M.dim))\n",
    "params = (x[0]+.1*np.random.normal(size=M.dim),.5)\n",
    "params_inds = (0,4)\n",
    "# function to update charts for position depends parameters\n",
    "def params_update(state, chart):\n",
    "    try:\n",
    "        ((x,m,v),),*s = state\n",
    "        if M.do_chart_update((x,chart)):\n",
    "            new_chart = M.centered_chart((x,chart))\n",
    "            (x,chart) = M.update_coords((x,chart),new_chart)\n",
    "        return optimizers.OptimizerState(((x,m,v),),*s),chart\n",
    "    except ValueError: # state is packed\n",
    "        states_flat, tree_def, subtree_defs = state\n",
    "        ((x,m,v),*s) = states_flat\n",
    "        if M.do_chart_update((x,chart)):\n",
    "            new_chart = M.centered_chart((x,chart))\n",
    "            (x,chart) = M.update_coords((x,chart),new_chart)\n",
    "        states_flat = ((x,m,v),*s)\n",
    "        return (states_flat,tree_def,subtree_defs),chart\n",
    "\n",
    "(thetas,chart,log_likelihood,log_likelihoods,thetass) = iterative_mle((samples,charts_samples),\n",
    "                                                                      neg_log_p_Ts,\n",
    "                                                                      params,params_inds,params_update,x[1],\n",
    "                                                                      num_steps=20)\n",
    "\n",
    "# plot\n",
    "n_steps = log_likelihoods.shape[0]\n",
    "plt.plot(range(n_steps),log_likelihoods)\n",
    "# plt.savefig('ML_likelihoods.pdf')\n",
    "plt.show()\n",
    "plt.plot(range(n_steps),[t[1] for t in thetass])\n",
    "plt.show()\n",
    "plt.plot(range(n_steps),[M.F((t[0],t[2])) for t in thetass])\n",
    "print(M.F((thetas[0],chart)))\n",
    "# plt.savefig('ML_thetas.pdf')\n",
    "plt.show()\n",
    "\n",
    "M.newfig()\n",
    "M.plot()\n",
    "M.plotx((thetas[0],chart),color='k',s=100) # result\n",
    "M.plotx((thetass[0][0],thetass[0][2]),color='b',s=100) # initial point\n",
    "M.plotx(x,color='r',s=100)\n",
    "M.plot_path(list([(t[0],t[2]) for t in thetass]),color='b',linewidth=2.5)\n",
    "\n",
    "plt.savefig('MLmean_iterations.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Most probable paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Anisotropic covariance on manifolds and most probable paths,\n",
    "# Erlend Grong and Stefan Sommer, 2021\n",
    "from src.framebundle import MPP\n",
    "MPP.initialize(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "from src.framebundle import FM\n",
    "FM.initialize(M)\n",
    "from src.stochastics import stochastic_development\n",
    "stochastic_development.initialize(M)\n",
    "\n",
    "# simulate Brownian Motion\n",
    "# %time _,xss,chartss=jax.vmap(lambda dWs: M.Brownian_coords(x,dWs))(dWs(M.dim,n_steps=1000,num=16))\n",
    "# obss = xss[:,-1]\n",
    "# obs_charts = chartss[:,-1]\n",
    "\n",
    "# simulate anisotropic Brownian Motion\n",
    "lamb = jnp.array([.6,.25])\n",
    "nu = jnp.einsum('i,ij->ij',lamb,np.linalg.cholesky(M.gsharp(x)))\n",
    "u = (np.concatenate((x[0],nu.flatten())),x[1])\n",
    "(ts,us,charts) = M.stochastic_development(u,dts(),dWs(M.dim))\n",
    "xs = us[:,0:M.dim]\n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "M.plot_path(zip(us,charts))\n",
    "plt.show()\n",
    "\n",
    "%time _,uss,chartss=jax.vmap(lambda dWs: M.stochastic_development(u,dts(),dWs))(dWs(M.dim,num=64))\n",
    "obss = uss[:,-1,0:M.dim]\n",
    "obs_charts = chartss[:,-1]\n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "for (_x,_chart) in zip(obss,obs_charts):\n",
    "    M.plotx((_x,_chart))\n",
    "plt.savefig('S2_samples_lamb_05_005.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Riemannian import curvature\n",
    "curvature.initialize(M)\n",
    "\n",
    "ys = list(zip(obss,obs_charts))\n",
    "chart = x[1]\n",
    "(_x,_lamb,vs,chis) = M.MPP_mean(x,chart,ys)\n",
    "\n",
    "# # compute variance\n",
    "# var = 1/(N*M.dim)*jnp.sum(jnp.array([f(chart,_x,_lamb,v,chi) for (v,chi) in get_params45(opt_state45)]))\n",
    "# print(_lamb,var)\n",
    "# # _lamb = _lamb*var\n",
    "# # print(_lamb)\n",
    "\n",
    "# print(lamb/jnp.sqrt(jnp.prod(lamb)))\n",
    "# print(_lamb/jnp.sqrt(jnp.prod(_lamb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_nu = jnp.linalg.cholesky(M.gsharp((_x,chart)))\n",
    "print(\"x: \",(_x,chart),\"\\nlambda:\\n\",_lamb,\"\\nnu:\\n\",_nu)\n",
    "_u = (jnp.hstack((_x,_nu.flatten())),chart)\n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "M.plotx((_x,chart),u=np.einsum('i,ij->ij',_lamb,_nu),linewidth = 1.5, s=50)\n",
    "\n",
    "for i in range(len(vs)):\n",
    "    v = vs[i]\n",
    "    chi = chis[i]\n",
    "\n",
    "    (xs,_,_chis,charts) = M.MPP_forwardt(_u,_lamb,v,chi)\n",
    "    print(\"v: \",v,\", chi: \",chi, \", chiT: \",_chis[-1])\n",
    "\n",
    "    \n",
    "    M.plotx((obss[i],obs_charts[i]),linewidth = 1.5, s=50, color='r')\n",
    "    M.plot_path(zip(xs[:,0:M.dim],charts))\n",
    "    \n",
    "plt.axis('off')\n",
    "# plt.savefig('S2_estimation_lambda_06_025.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
